\documentclass[../main.tex]{subfiles}

\chapter{Discussion}\label{discussion}
\section{Problems and Challenges}
In this section, I wish to discuss and explain some of the problems or suboptimal solution used in the implementation of the Sensor Server. Some of the solutions should probably be fixed before an eventual deployment. These solution were scheduled to be improved but was not prioritized due to lack of time. 

\subsection{Resizing shared memory segments}\label{resizing_shared}
Ideally, the shared memory segments containing the client list should be resize-able and the size should depend on the number of connected clients. This proved difficult and I was not able to implement it. M. Kerrisk explains in his "The Linux Programming Interface" \cite{kerrisk2010linux}, that most UNIX implementations does not support resizing of a memory map like the shared memory segments used in the Sensor Server. However, there is a non-portable and Linux specific system call, \texttt{mremap()} that can be used on Linux system for this purpose. Unfortunately, the address returned by \texttt{mremap()} might be different from the old address to the shared memory segment. This would mean that pointer inside the shared segment might no longer be valid after a resize operation has been done. A way to avoid this problem caused by the remapping, would be to use offsets instead of pointers when referring to addresses in the mapped region. While troubleshooting problems I had using \texttt{mremap()}, I stumbled upon a bug report reported to the Kernel Bug Tracker \cite{BUG_TRACK} describing similar issues as I was having. This indicate that the trouble I was having might be because of a bug in the Linux kernel. I have yet to confirm this, but it did convince me to leave the implementation with its shortcomings rather than potentially wasting my time on something way out of my reach. The waste of memory would never by substantial anyway, considering that the size of the \texttt{client\_table\_entry} struct is a mere 4664 bytes. 

\subsection{Usage of scripts}
In the current implementation of the Sensor Server, two scripts are used as part of the main routine. The first one is the \texttt{query\_csac.py}. This is a python script that was originally written to log data from atomic clock during data acquisition \ref{data_aquisition}. For some reason, it proved to be a significant challenge to implement a solution in C to configure, read and write from the atomic clock. The best solution did not even provide a reliable means of communicating with the atomic clock, even though communication with the GPS receivers, which in theory should have been exactly the same, was no problem. Once time got tight, I made the decision to drop the development of the atomic clock serial communication module written in C, and decided to use \texttt{query\_csac.py} by invoking with \texttt{popen()}. The story is much the same with the second script, \texttt{get\_mjd.py}. This is a script that calculates the Modified Julian date, a time format that is heavily used in calculations done by the clock model. The script relies on a library named jdutil.py, written by Matt Davis \cite{MATT_DAVIS}. Permission to use the jdutil.py was granted by Mr. Davis. The correspondence with Mr. Davis is included in the appendix under \ref{davis_email}.

\section{Currently missing}
This section is used to discuss some of the shortcomings in the current version of the Sensor Server. Some functions were never implemented and others were not finished.

\subsection{Atomic clock management}
The Sensor Server should have had a separate process that handled the filters and communication with the atomic clock. This would free the processes handling the connections, from dealing with the filters and make the filter abstraction more complete and make the atomic clock model cleaner. The atomic clock model is already logically separated from the filters associated with it, but because of the way the code is organized, the use of the model implies the use of the filter. The atomic clock should still communicate with the atomic clock on its own like it does today, retrieving telemetry data, but the aforementioned process could keep track of the atomic clock's discipline status, steering and other functionality thus creating a more generic way for the system to communicate with the atomic clock. The GPS based filter could greatly benefit from this approach, as they today are not currently doing anything but log occurrences where they were triggered. 

\section{Choice of programming language}
The SMACC software was originally planned to be written in Java since this was my most fluent programming language. Java is great language, it's object oriented, it has a garbage collector and a lot of useful libraries. As development started, it quickly became apparent that some parts of the code would be performance critical and that portability really wasn't that important anyway. The platform was already decided and there was no reason to believe that it would change in the near future. As we all know, premature optimization is the root of all evil. Being reluctant to commit a deadly programming sin, i decided to look at other languages. Since performance was a concern, Python was also quickly dismissed as an option. C++ would probably have been the best choice, but having never written anything in C before made it sound more exciting and like a nice opportunity to learn something new. During the planning phase of SMACC development, raspbian-2015-05-07 was the latest build. It came with GCC 4.6.3 which only had experimental support for C11(\cite{GCC11}). With C11 no longer considered an option, C99 was the obvious choice given it's attractive features like:
\begin{itemize}
  \item Variable-length arrays.
  \item Single line comments.
  \item snprintf() as standard (\cite{C_RATIONAL}).
\end{itemize}

\section{Alternative approaches}\label{da}
When planning on how to execute our proposal, these were among the ideas that came up. 

\subsection{Single computer, many GNSS receivers}\label{scmgr}
A single computer is used to run the SMACC software. The SMACC does not include a Server/Cient model, but the receivers used to collect data are all connected to to the computer through whatever USB ports available or made available by the use of USB hubs. With this approach, you are not dependent on a network, but it limits the number of GNSS receivers you could connect as the USB specification limits the number possible endpoints to an absolute 127(\cite[pp. 3]{USBTC}) because of addressing. This does not mean that 127 devices can be connected, a single device might use more than one endpoint. It's also worth mentioning that a USB hub might "reserve" multiple endpoints. Depending on the GNSS receivers and how they are made, this number might be reduced even further by the power usage of the connected devices. Depending on how far each GNSS receiver is distanced from the SMACC, a signal amplifier might be necessary to compensate for the signal attenuation. In some cases where a network is absent, this might be only option.

\subsection{Store in database and analyze}
With this approach, the idea of a GNSS receiver and RASPI as a single "sensor" unit is the same as with Client-server approach. The difference is that it with this approach, each sensor stores the collected data in a database. The SMACC software monitors the clock directly as with the Client-server approach, but the data in the database is routinely queried and analyzed. The strength with this approach is that data is easily stored, shared and maintained by a single entity. The complexity of the client software would be the same as with Client-server approach, but the SMACC software could be implemented with less complexity as no Client-server architecture or shared memory schemes would be necessary. During planning, this approach seemed promising but was rejected because it was thought that it might not be time-sensitive enough. It was also some doubt concerning whether or not the ability to store data to a database actually was important. Once the different filters and algorithms was in place, it turned that the database functionality would have been nice, but not of any real importance for the SMACC to perform it's tasks, and would have been overkill anyway.